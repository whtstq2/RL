# Finite Markov Decision Process

유한한 MDP에 대한 챕터이다. 
MDP 문제는 가장 기본적인 문제이다. 
연속으로 결정을 내려야하는 문제이고 action시 즉각적인 reward를 받는게 아닐 수도 있다. 
그래서 즉시 얻는 보상과 나중에 얻게되는 보상의 기준을 정하는게 중요하다. Bandit의 경우엔 각 action마다 true value가 있었다. 하지만 MDP에선 action만이 아니라 state까지 고려하여 true value를 추정한다. 또는 최적의 action을 통해 각 상태의 값v을 추정한다. 
이 state-dependent quantities 들은 long-term 사건이 일어날때 

> Written with [StackEdit](https://stackedit.io/).
<!--stackedit_data:
eyJoaXN0b3J5IjpbLTE2MDA3NzM1NjIsLTEyODE0MDE5NzAsNj
g2NDIwMzIwLDc2MDE2NDM3MywtMjE3NTgwMzE3XX0=
-->