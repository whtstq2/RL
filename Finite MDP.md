# Finite Markov Decision Process

유한한 MDP에 대한 챕터이다. 
MDP 문제는 가장 기본적인 문제이다. 
연속으로 결정을 내려야하는 문제이고 action시 즉각적인 reward를 받는게 아닐 수도 있다. 
그래서 즉시 얻는 보상과 나중에 얻게되는 보상의 기준을 정하는게 중요하다. Bandit의 경우엔 각 행동마다 정해진 reward가 있었다. 하지만 MDP에선 

> Written with [StackEdit](https://stackedit.io/).
<!--stackedit_data:
eyJoaXN0b3J5IjpbLTY0MzQ0ODcxMCwtMjE3NTgwMzE3XX0=
-->